# Text Generation with RNNs

## Overview
This Assignment explores text generation using deep learning models, specifically Recurrent Neural Networks (RNNs). The goal is to train a model to predict the next word in a sequence, generating meaningful text.

## Dataset

The dataset consists of Shakespeare's works, which are tokenized to train the model. This allows the model to learn the structure and style of the text.

## Model Architectures

The project implements three types of RNN models:

1. LSTM (Long Short-Term Memory)

2. GRU (Gated Recurrent Unit)

3. Bidirectional RNN

