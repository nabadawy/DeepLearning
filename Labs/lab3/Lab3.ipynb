{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjG7R65B1YyT"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/sherifmost/DeepLearning/blob/master/Labs/lab3/Lab3.ipynb\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/colab.png?v2.0\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgfMPjgq1oES"
      },
      "source": [
        "# Assignment 3: Convolutional Neural Network Use Cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9itO8bK5U2j"
      },
      "source": [
        "![Simple CNN](https://github.com/sherifmost/DeepLearning/blob/master/Labs/lab3/Cover.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jddEsdkXvrRw"
      },
      "source": [
        "## 3.1 Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzc_iwgHvf4U"
      },
      "source": [
        "In this assignment you will build several CNN models that check if a person is happy or not. You will use custom made CNN, and CNN use cases either pretrained or not, also you will apply layers freezing on pretrained CNNs and study all those modifications effect on the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf0ytuSvvxr4"
      },
      "source": [
        "**IMPORTANT NOTE:** You have to change runtime type on Google Colab to GPU since the CNN models used require much computation resources and it will run very slowly on CPU (Default runtime type)\n",
        "\n",
        "Click on \"Runtime\" => \"Change runtime type\" => make sure that GPU is selected in the \"Hardware accelerator\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIDR25n6wpFs"
      },
      "source": [
        "## 3.2 Problem Details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w2cdFNgwzCZ"
      },
      "source": [
        "### 3.2.1 Packages & Utility Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you check the imported modules as they can help you later on"
      ],
      "metadata": {
        "id": "VgeyEX_lbkmB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I43CQb7jw4EU"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# you can use this library for resizing the images if you want\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import applications\n",
        "import tensorflow.keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "from IPython.display import SVG\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "import pydot\n",
        "import h5py\n",
        "import random\n",
        "import requests\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs2VOP_DxLrX"
      },
      "source": [
        "def download_file(file_url):\n",
        "    file_r = requests.get(file_url, allow_redirects=True)\n",
        "    open(file_url.rsplit('/', 1)[1], 'wb').write(file_r.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E30_iWRoxO5c"
      },
      "source": [
        "### 3.2.2 Dataset Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJqYhRtSxoGH"
      },
      "source": [
        "#### Define method to download & load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7X-DKCxxSnx"
      },
      "source": [
        "def load_dataset():\n",
        "    download_file(\"https://raw.githubusercontent.com/KhaledElTahan/DeepLearning/master/Labs/lab3/lab3_train.h5\")\n",
        "    download_file(\"https://raw.githubusercontent.com/KhaledElTahan/DeepLearning/master/Labs/lab3/lab3_test.h5\")\n",
        "\n",
        "    path_to_train = \"lab3_train.h5\"\n",
        "    path_to_test = \"lab3_test.h5\"\n",
        "\n",
        "    train_dataset = h5py.File(path_to_train, \"r\")\n",
        "    train_x = np.array(train_dataset['train_set_x'][:])\n",
        "    train_y = np.array(train_dataset['train_set_y'][:])\n",
        "\n",
        "    test_dataset = h5py.File(path_to_test, \"r\")\n",
        "    test_x = np.array(test_dataset['test_set_x'][:])\n",
        "    test_y = np.array(test_dataset['test_set_y'][:])\n",
        "\n",
        "    # reshape y from (samples, ) to (1, samples)\n",
        "    train_y = train_y.reshape((1, train_x.shape[0]))\n",
        "    test_y = test_y.reshape((1, test_x.shape[0]))\n",
        "\n",
        "    # transpose y\n",
        "    train_y = train_y.T\n",
        "    test_y = test_y.T\n",
        "\n",
        "    return train_x, train_y, test_x, test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q76lKFO4xfYl"
      },
      "source": [
        "#### Define method to make simple preprocessing on the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtZ8CqeixgNf"
      },
      "source": [
        "def preprocess_data():\n",
        "    train_x, train_y, test_x, test_y = load_dataset()\n",
        "\n",
        "    # Normalize image vectors\n",
        "    train_x = train_x/255.\n",
        "    test_x = test_x/255.\n",
        "\n",
        "    print (\"number of training examples = \" + str(train_x.shape[0]))\n",
        "    print (\"number of test examples = \" + str(test_x.shape[0]))\n",
        "\n",
        "    print (\"X_train shape: \" + str(train_x.shape))\n",
        "    print (\"Y_train shape: \" + str(train_y.shape))\n",
        "    print (\"X_test shape: \" + str(test_x.shape))\n",
        "    print (\"Y_test shape: \" + str(test_y.shape))\n",
        "\n",
        "    return train_x, train_y, test_x, test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k4p45YfxjE6"
      },
      "source": [
        "#### Get the preprocessed Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRj85-HdxjZ9"
      },
      "source": [
        "# Obtaining the training and testing data\n",
        "train_x, train_y, test_x, test_y = preprocess_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7lCvXryXEf"
      },
      "source": [
        "### 3.2.3 Dataset Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvIrHn8Ry2yH"
      },
      "source": [
        "W_grid = 6\n",
        "L_grid = 6\n",
        "\n",
        "fig, axes = plt.subplots(L_grid, W_grid, figsize = (9,9))\n",
        "\n",
        "axes = axes.ravel() # flaten the L_grid x W_grid matrix into L_grid * W_grid array\n",
        "\n",
        "n_training = len(train_x) # get the length of the training dataset\n",
        "\n",
        "for i in np.arange(0, W_grid * L_grid): # create evenly spaces variables\n",
        "\n",
        "    index = np.random.randint(0, n_training)\n",
        "    axes[i].imshow(train_x[index])\n",
        "\n",
        "    if train_y[index] == 1:\n",
        "        axes[i].set_title(\"Happy\", fontsize = 10)\n",
        "    else:\n",
        "        axes[i].set_title(\"Not Happy\", fontsize = 10)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(hspace=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pFEjlqqzq9S"
      },
      "source": [
        "### 3.2.4 Plot Utility Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvx-fYE--Oe5"
      },
      "source": [
        "The following code is used to plot accuracy and loss histories for each model experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-xg8Tb49prm"
      },
      "source": [
        "def plot(training_results, validation_results, results_type, model_name):\n",
        "    fig = plt.figure(figsize=[8, 6])\n",
        "\n",
        "    plt.plot(training_results, 'r', linewidth=3.0)\n",
        "    plt.plot(validation_results, 'b', linewidth=3.0)\n",
        "    plt.legend(['Training ' + results_type, 'Validation ' + results_type], fontsize=18)\n",
        "    plt.xlabel('Epochs', fontsize=16)\n",
        "    plt.ylabel(results_type, fontsize=16)\n",
        "    plt.title(results_type + ' of ' + model_name, fontsize=16)\n",
        "\n",
        "\n",
        "def plot_accuracy(history, model_name):\n",
        "    plot(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', model_name)\n",
        "\n",
        "\n",
        "def plot_loss(history, model_name):\n",
        "    plot(history.history['loss'], history.history['val_loss'], 'Loss', model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAQaHBS7_5Ep"
      },
      "source": [
        "### 3.2.5 Custom CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAuIspNRBCwE"
      },
      "source": [
        "**TODO**: Build a custom CNN model to solve the problem.\n",
        "\n",
        "Model guidelines **(You need to follow them)**:\n",
        "\n",
        "1. [Input](https://keras.io/api/layers/core_layers/input/) Layer.\n",
        "2. [ZeroPadding2D](https://keras.io/api/layers/reshaping_layers/zero_padding2d/) Layer.\n",
        "3. [Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d/) Layer.\n",
        "4. [BatchNormalization](https://keras.io/api/layers/normalization_layers/batch_normalization/) Layer. You can read [this article](https://kharshit.github.io/blog/2018/12/28/why-batch-normalization) to learn more about BatchNormalization.\n",
        "5. Relu [Activation](https://keras.io/api/layers/core_layers/activation/).\n",
        "6. [MaxPooling2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/) Layer.\n",
        "7. [Flatten](https://keras.io/api/layers/reshaping_layers/flatten/) Layer.\n",
        "8. [Dense](https://keras.io/api/layers/core_layers/dense/) with Sigmoid activation (one perceptron).\n",
        "\n",
        "**Note**: If you made the required model, you can make other custom CNN models **if you wish** to further improve the accuracy, but in other code cells however.\n",
        "\n",
        "**Note**: the code provided below uses the tensorflow [functional API](https://www.tensorflow.org/guide/keras/functional) in building the model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make sure to add the following to the report:**\n",
        "\n",
        "\n",
        "*   The plot and accuracy achieved using the custom model at the end of the notebook (1.1 in the report)\n",
        "*   **Optional**: The changes, plots, and accuracies achieved using other custom model variations (the optional question in part 1 in the report)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ncb1QBu5x9_X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QL8GOa0A0hg"
      },
      "source": [
        "def CustomCNN(input_shape):\n",
        "    \"\"\"\n",
        "    Implementation of the Custom CNN.\n",
        "    Args:\n",
        "        input_shape () shape of the images of the dataset\n",
        "    Returns:\n",
        "        model (Keras.Model): CNN Custom Model\n",
        "        model_name (Str): The name of the model\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    X_input = ''' TODO: Define the input layer '''\n",
        "\n",
        "    # Zero-Padding: pads the border of X_input with zeroes\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # CONV -> BN -> RELU Block applied to X\n",
        "    # Choose a suitable number of filters and kernel size\n",
        "    X = '''TODO: Define the conv2d layer'''\n",
        "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
        "    X = '''TODO: Define the Relu activation layer'''\n",
        "\n",
        "    # MAXPOOL\n",
        "    X = '''TODO: Define the maxpooling2d layer'''\n",
        "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED (Dense)\n",
        "    X = Flatten()(X)\n",
        "    Y = '''TODO: Define the output dense layer'''\n",
        "\n",
        "    # Create model. This creates your tensorflow.keras model instance, you'll use this instance to train/test the model.\n",
        "    model = Model(inputs=X_input, outputs=Y)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return model, \"Custom CNN\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHYRpliRENqH"
      },
      "source": [
        "### 3.2.6 CNN Use Case No.1: VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYMN2-ECFsRg"
      },
      "source": [
        "![VGG Architecture](https://github.com/sherifmost/DeepLearning/blob/master/Labs/lab3/vgg.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fonIfjJOFzCU"
      },
      "source": [
        "**Note**: this ia a show case to help you do the same with other use cases.\n",
        "\n",
        "**TODO**: Try different variations for VGG:\n",
        "\n",
        "1. [VGG16](https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16)\n",
        "2. [VGG19](https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG19)\n",
        "\n",
        "**Note**: *You will need to experiment all of them both pretrained (both with or without layers freezing) and also untrained, in the test section.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make sure to add the following to the report:**\n",
        "\n",
        "\n",
        "*   The plots and accuracy achieved using VGG16 untrained, pre-trained, and pre-trained with layer freezing with different number of frozen layers (from 2.1 till 2.5 in the report)\n",
        "*   The plots and accuracy achieved using VGG19 untrained, pre-trained, and pre-trained with layer freezing with different number of frozen layers (from 2.6 till 2.10 in the report)\n",
        "\n"
      ],
      "metadata": {
        "id": "OMcMjADFQ49w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXdxqjb1EVfr"
      },
      "source": [
        "def VGG(pretrained = True, input_shape = (64, 64, 3), model_name = \"VGG16\"):\n",
        "    \"\"\"\n",
        "    Returns VGG Keras Model\n",
        "    Args:\n",
        "        pretrained (Bool): Whether get a pretrained model or not\n",
        "        input_shape (Tuple): To create the input layer, should match the image resolution\n",
        "        model_name (str): String to capture the model name\n",
        "    Examples:\n",
        "        VGG(True) -> Model, \"Pretrained VGG16\"\n",
        "    \"\"\"\n",
        "    if(pretrained):\n",
        "        model_name = \"Pretrained \" + model_name\n",
        "        base_model = applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=input_shape, pooling='none')\n",
        "    else:\n",
        "        model_name = \"Untrained \" + model_name\n",
        "        base_model = applications.vgg16.VGG16(weights=None, include_top=False, input_shape=input_shape, pooling='none')\n",
        "\n",
        "    return base_model, model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeoGhvJbEVzf"
      },
      "source": [
        "### 3.2.7 CNN Use Case No.2: Residual Connections-based Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzFQlFBIJZT6"
      },
      "source": [
        "![VGG vs ResNet](https://github.com/sherifmost/DeepLearning/blob/master/Labs/lab3/VGG_vs_ResNet.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnJAoDo0Jdoh"
      },
      "source": [
        "**TODO**: Follow the same style for the above mentioned VGG and experiment the following Networks:\n",
        "\n",
        "1. [ResNet50](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50)\n",
        "2. [ResNet101](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet101)\n",
        "3. [InceptionResNetV2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_resnet_v2/InceptionResNetV2) this network builds on the inception network architecture and incorporates [residual connections](https://towardsdatascience.com/what-is-residual-connection-efb07cab0d55), you can read more about it [here](https://paperswithcode.com/method/inception-resnet-v2#:~:text=Inception%2DResNet%2Dv2%20is%20a,stage%20of%20the%20Inception%20architecture).\n",
        "\n",
        "**Note 1**: *You will need to experiment all of them both pretrained (both with or without layers freezing) and also untrained, in the test section.*\n",
        "\n",
        "**Note 2**: For very deep networks like **InceptionResNetV2**, the size of the input might get reduced too much and an error might be produced, **you need to fix this issue by either resizing the images (preferred) or by adding padding (not preferred)**.\n",
        "\n",
        "To resize the image you *can* follow the following steps (*just some possible guidelines)*:\n",
        "\n",
        "*   You can use [cv2.resize](https://www.geeksforgeeks.org/image-resizing-using-opencv-python/) or [tf.image.resize](https://www.tensorflow.org/api_docs/python/tf/image/resize).\n",
        "*   Make a function similar to preprocess_data() but instead resize the train and test images before returning them at the end\n",
        "*   When you train the model that is causing the error, call the new function you made to obtain the training and testing data instead of calling the original preprocess_data() *(as was done at the beggining of the notebook)*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make sure to add the following to the report:**\n",
        "\n",
        "\n",
        "*   The plots and accuracy achieved using ResNet50 untrained, pre-trained, and pre-trained with layer freezing with different number of frozen layers (from 3.1 till 3.5 in the report)\n",
        "*   The plots and accuracy achieved using ResNet101 untrained, pre-trained, and pre-trained with layer freezing with different number of frozen layers (from 3.6 till 3.10 in the report)\n",
        "*   The plots and accuracy achieved using InceptionResNetV2 untrained, pre-trained, and pre-trained with layer freezing with different number of frozen layers (from 3.11 till 3.15 in the report)\n",
        "\n"
      ],
      "metadata": {
        "id": "QfGL-9MHTe6w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blCAcLhOEgxV"
      },
      "source": [
        "# The ResNet function refers to the above residual connection-based networks including the InceptionResNetV2 network\n",
        "def ResNet(pretrained = True, input_shape = (64, 64, 3), model_name = \"ResNet50\"):\n",
        "    \"\"\"\n",
        "    Returns ResNet Keras Model\n",
        "    Args:\n",
        "        pretrained (Bool): Whether get a pretrained model or not\n",
        "        input_shape (Tuple): To create the input layer, should match the image resolution\n",
        "        model_name (str): String to capture the model name\n",
        "    Examples:\n",
        "        ResNet(True) -> Model, \"Pretrained ResNet50\"\n",
        "    \"\"\"\n",
        "    if(pretrained):\n",
        "        model_name = \"Pretrained \" + model_name\n",
        "        base_model = '''TODO: Define the pretrained model using keras.applications'''\n",
        "    else:\n",
        "        model_name = \"Untrained \" + model_name\n",
        "        base_model = '''TODO: Define the pretrained model using keras.applications'''\n",
        "\n",
        "    return base_model, model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSnsFbYpEhQ-"
      },
      "source": [
        "### 3.2.8 CNN Use Case No.3: Your choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y962x5Z6KIXV"
      },
      "source": [
        "**TODO**: Select one application other than VGG or ResNet from [here](https://www.tensorflow.org/api_docs/python/tf/keras/applications) and implement it the same way you did with VGG & ResNet.\n",
        "\n",
        "**Note**: *You will need to experiment it in both pretrained (both with or without layers freezing) and also untrained, in the test section.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make sure to add the following to the report:**\n",
        "\n",
        "\n",
        "*   The name of the chosen model, plots and accuracy achieved using this model untrained, pre-trained, and pre-trained with layer freezing with different number of frozen layers (from 4.1 till 4.5 in the report)\n"
      ],
      "metadata": {
        "id": "2ALZy81WVjgW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeUM8gMSEnky"
      },
      "source": [
        "def CNN_App(pretrained = True, input_shape = (64, 64, 3), model_name = 'Name your Chosen CNN APP Here'):\n",
        "    \"\"\"\n",
        "    Returns A Custom CNN Application Keras Model\n",
        "    Args:\n",
        "        pretrained (Bool): Whether get a pretrained model or not\n",
        "        input_shape (Tuple): To create the input layer, should match the image resolution\n",
        "        model_name (str): String to capture the model name\n",
        "    Examples:\n",
        "        CNN_App(True, (64, 64, 3), \"Xception\") -> Model, \"Pretrained Xception\"\n",
        "    \"\"\"\n",
        "    if(pretrained):\n",
        "        model_name = \"Pretrained \" + model_name\n",
        "        base_model = '''TODO: Define the pretrained model using keras.applications'''\n",
        "    else:\n",
        "        model_name = \"Untrained \" + model_name\n",
        "        base_model = '''TODO: Define the untrained model using keras.applications'''\n",
        "\n",
        "    return base_model, model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8yZbaVmEoFo"
      },
      "source": [
        "### 3.2.9 Layers Freezing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoI_aoqqLaSB"
      },
      "source": [
        "The following utility method is used for layers freezing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmHk7MPbMYLt"
      },
      "source": [
        "**TODO**: *Experiment all the pretrained models with layers freezing using* **different number of frozen layers**.\n",
        "\n",
        "**NOTE**: You will not change this method at all, the experimenting will take place in the test cases section below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtjg2Emd9vid"
      },
      "source": [
        "def freeze(model, number_of_frozen_layers):\n",
        "    layers = model.layers\n",
        "\n",
        "    layers = layers[:number_of_frozen_layers]\n",
        "\n",
        "    for layer in layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Upxm_gfL4Z6"
      },
      "source": [
        "### 3.2.10 Make your models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-KBFF_3L8TB"
      },
      "source": [
        "You can use the following utility method to make the model you desire, **modify it if you please**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKSOIuhmL5Ka"
      },
      "source": [
        "def make_model(pretrained=True, freeze_layers=False, number_of_frozen_layers=0, model_selection=\"VGG\"):\n",
        "    \"\"\"\n",
        "    Use this method to create models\n",
        "    Args:\n",
        "      pretrained (Bool): Whether make the model pretrained or not, doesn't apply to custom CNN.\n",
        "      freeze_layers (Bool): Whether apply layers freezing on pretrained networks or not.\n",
        "      number_of_frozen_layers (int): Number of frozen layers.\n",
        "      model_selection (Str): Must be exactly \"Custom\", or \"VGG\", or \"ResNet\" or anything else for CNN_App\n",
        "    \"\"\"\n",
        "    # ==================================================================== TAKE CARE ==========================================================================\n",
        "    # You might need to make the input shape an additional parameter to the function instead of being statically defined here\n",
        "    # This will help you configure the input_shape when you handle the error due to the vanishing input dimensions in very deep networks like inception_resnetV2\n",
        "    input_shape = (64, 64, 3)\n",
        "\n",
        "    if model_selection == \"Custom\":\n",
        "        model, model_name = CustomCNN(input_shape)\n",
        "    elif model_selection == \"VGG\":\n",
        "        model, model_name = VGG(pretrained, input_shape)\n",
        "    elif model_selection == \"ResNet\":\n",
        "        model, model_name = ResNet(pretrained, input_shape)\n",
        "    else:\n",
        "        model, model_name = CNN_App(pretrained, input_shape)\n",
        "\n",
        "    if model_selection != \"Custom\":\n",
        "        if freeze_layers:\n",
        "            model = freeze(model, number_of_frozen_layers)\n",
        "            model_name = model_name + \" with \" + str(number_of_frozen_layers) + \" Frozen Layers\"\n",
        "\n",
        "        ## Add classification head for non custom models\n",
        "        y = model.output\n",
        "        y = Flatten()(y)\n",
        "        y = Dense(256, activation='relu')(y)\n",
        "        y = Dense(1, activation='sigmoid', name='fc')(y)\n",
        "\n",
        "        model = Model(inputs=model.input, outputs=y)\n",
        "\n",
        "    return model, model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRYxqJQP-c5j"
      },
      "source": [
        "### 3.2.11 Testing model utility method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-rtiZGC_610"
      },
      "source": [
        "This is a generic method that will be used to test all the implemented models, a modular design allows you to experiment more clearly. **Modify it if you please.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaJUEXAq_NSX"
      },
      "source": [
        "**TODO**:\n",
        "\n",
        "1. Try different [optimizers](https://keras.io/api/optimizers/) and report their affect on the **results** and plots.\n",
        "2. For each optimizer, try different learning rates and other hyperparameters (If applicable), and report the difference on the **results** and plots.\n",
        "3. Try different [loss functions](https://keras.io/api/losses/), and report their affect on **accuracy** and plots.\n",
        "\n",
        "**IMPORTANT NOTE**: You don't need to try different optimizers, learning rates and hyperparameters, and losses on all models, **just find the best model with the current optimizers, rates and hyperparameters & losses** **then try your experiments** (changing optimizers, rates and hyperparameters & losses) only on this best model.\n",
        "\n",
        "***The best model is obtained after testing the different models defined above in different cases (untrained, pretrained without freezing, and pretrained with different number of frozen layers) and choosing the model case giving the best performance***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make sure to add the following to the report:**\n",
        "\n",
        "\n",
        "*   The best model found and its accuracy before tuning (5.1 in the report)\n",
        "*   Include the default case for the optimizer and its hyperparameters using SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True) (5.2 in the report)\n",
        "*   Experiment with other combinations of optimizers and their hyperparameters (5.3, 5.4, 5.5, 5.6 in the report)\n",
        "*   Include the default case for the loss using Binary Crossentropy (5.7 in the report)\n",
        "*   Try out two other loss functions (5.8, 5.9 in the report)\n"
      ],
      "metadata": {
        "id": "2ZbYhajRYb91"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9UnOPkv9qSs"
      },
      "source": [
        "def test_model(model, model_name, epochs=10, print_summary=True, plot_results=True):\n",
        "    '''TODO: Experiment with different optimizers, learning rates and hyperparameters, and losses on the best model'''\n",
        "\n",
        "    sgd = SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
        "    model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    if (print_summary):\n",
        "        model.summary()\n",
        "\n",
        "    hist = model.fit(train_x, train_y, validation_data = (test_x, test_y), verbose=1, epochs=epochs, batch_size=32)\n",
        "    preds = model.evaluate(test_x, test_y, batch_size=32, verbose=1, sample_weight=None)\n",
        "\n",
        "    print (\"Validation Loss = \" + str(preds[0]))\n",
        "    print (\"Validation Accuracy = \" + str(preds[1]))\n",
        "\n",
        "    if(plot_results):\n",
        "        plot_loss(hist, model_name)\n",
        "        plot_accuracy(hist, model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQDz5f_6PfdE"
      },
      "source": [
        "### 3.2.12 Create your model test cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFi_kXqISPCC"
      },
      "source": [
        "**TODO**: Fill here all the test cases methods that you want to apply.\n",
        "\n",
        "Add methods (Untrained, pretrained & pretrained with freezing) for *(at least)*:\n",
        "1. ResNet()\n",
        "2. CNN_App()\n",
        "\n",
        "**NOTE**: *Those test cases, don't change use case types (i.e. you will need to change the VGG in VGG() method to VGG19 and re test again or make another function for VGG19 for example) and doesn't change the loss function nor the optimizer type (these need to be changed in the testing utility method).*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNx7FL_c9wKz"
      },
      "source": [
        "def test_custom_CNN(epochs=20, print_summary=True, plot_results=True):\n",
        "    model, model_name = make_model(False, False, 0, \"Custom\")\n",
        "    test_model(model, model_name, epochs, print_summary, plot_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tKg6sTF9ylX"
      },
      "source": [
        "def test_untrained_VGG(epochs=20, print_summary=True, plot_results=True):\n",
        "    model, model_name = make_model(False, False, 0, \"VGG\")\n",
        "    test_model(model, model_name, epochs, print_summary, plot_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yualvOIjR7Dp"
      },
      "source": [
        "def test_pretrained_VGG(epochs=20, print_summary=True, plot_results=True):\n",
        "    model, model_name = make_model(True, False, 0, \"VGG\")\n",
        "    test_model(model, model_name, epochs, print_summary, plot_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlgrrWDNSAqx"
      },
      "source": [
        "def test_pretrained_layers_freezing_VGG(epochs=20, print_summary=True, plot_results=True):\n",
        "    model, model_name = make_model(True, True, 5, \"VGG\")\n",
        "    test_model(model, model_name, epochs, print_summary, plot_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtAoevuYUE8v"
      },
      "source": [
        "###  3.2.13 Test your models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnUnFfDuVvQa"
      },
      "source": [
        "**TODO**: Call all your defined methods for testing here.\n",
        "\n",
        "**Note**: You might want to go up to **1000** epochs for the untrained model if the validation accuracy is low."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYs7qV-nUIy5"
      },
      "source": [
        "test_custom_CNN(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rqqdnGzULd-"
      },
      "source": [
        "test_untrained_VGG(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnZ-fSUTUNBz"
      },
      "source": [
        "test_pretrained_VGG(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouoa85_rUOwU"
      },
      "source": [
        "test_pretrained_layers_freezing_VGG(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntW1W4xGW6d-"
      },
      "source": [
        "## 3.3 Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TZBCoE7XAws"
      },
      "source": [
        "That's it! Congratulations on training CNN use cases models.\n",
        "\n",
        "Make sure you deliver all the requirements for the submission."
      ]
    }
  ]
}